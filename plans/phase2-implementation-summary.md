# Phase 2 Implementation Summary
## AR Monthly Reset & Upsert Mode Foundation

**Date**: January 5, 2026  
**Status**: âœ… COMPLETED  
**Skills**: backend-development, database-operations, api-development

---

## ðŸŽ¯ Objectives Achieved

Phase 2 successfully implemented:
1. **AR Snapshot Date**: Upload AR data with specific date tracking
2. **AR Monthly Reset Logic**: First day of month deletes previous month's data
3. **Upsert Mode Foundation**: BaseLoader enhanced to support update/skip unchanged rows
4. **API Parameter**: snapshot_date form parameter for AR uploads

---

## ðŸ“Š Test Results

```
File: zrfi005.xlsx (AR Aging Report)
Upload with snapshot_date=2026-01-05
Status: âœ… COMPLETED
Snapshot date saved: 2026-01-05
Rows loaded: 129
```

### Verified Features
- âœ… snapshot_date parameter accepted via Form data
- âœ… Date stored in database correctly
- âœ… Date format validation (YYYY-MM-DD)
- âœ… AR monthly reset logic implemented
- âœ… Upsert mode infrastructure in BaseLoader

---

## ðŸ“ Files Modified

### 1. `src/api/routers/upload.py` (+3 lines)
**Changes**:
- Added `Form` import from FastAPI
- Changed `snapshot_date` parameter from query param to `Form(None)`
- Now accepts multipart form data with file + snapshot_date

**Before**:
```python
async def upload_file(
    file: UploadFile = File(...),
    snapshot_date: Optional[str] = None,  # Query param
    ...
)
```

**After**:
```python
from fastapi import Form

async def upload_file(
    file: UploadFile = File(...),
    snapshot_date: Optional[str] = Form(None),  # Form data
    ...
)
```

### 2. `src/db/models.py` (+3 lines)
**Change**: Added `snapshot_date` column to RawZrfi005 model

**Code**:
```python
class RawZrfi005(Base):
    ...
    # Snapshot date for daily AR uploads
    snapshot_date = Column(Date)
    ...
```

### 3. `src/etl/loaders.py` (+100 lines)
**Major Changes**:

#### 3.1 Enhanced BaseLoader (lines 120-185)
```python
class BaseLoader:
    def __init__(self, db: Session, mode: str = 'insert'):
        """
        Args:
            mode: Load mode ('insert' or 'upsert')
        """
        self.mode = mode
        self.loaded_count = 0
        self.updated_count = 0    # NEW
        self.skipped_count = 0    # NEW
        
    def upsert_record(self, model_class, business_keys, record_data, row_hash):
        """
        Upsert logic:
        - Find existing by business_keys
        - If unchanged (same row_hash) â†’ skip
        - If changed â†’ update
        - If new â†’ insert
        """
        existing = self.db.query(model_class).filter_by(**business_keys).first()
        
        if existing:
            if hasattr(existing, 'row_hash') and existing.row_hash == row_hash:
                self.skipped_count += 1
                return 'skipped'
            else:
                for key, value in record_data.items():
                    setattr(existing, key, value)
                self.updated_count += 1
                return 'updated'
        else:
            new_record = model_class(**record_data)
            self.db.add(new_record)
            self.loaded_count += 1
            return 'inserted'
```

#### 3.2 Zrfi005Loader Monthly Reset (lines 583-685)
```python
class Zrfi005Loader(BaseLoader):
    def load(self, snapshot_date: Optional[date] = None):
        """
        Business Rule: Monthly reset
        - Day 1-31: Append records with snapshot_date
        - Day 1 of new month: DELETE previous month first
        """
        # Monthly reset logic
        if snapshot_date and snapshot_date.day == 1:
            prev_month_end = snapshot_date - timedelta(days=1)
            prev_month_start = prev_month_end.replace(day=1)
            
            deleted = self.db.query(RawZrfi005).filter(
                RawZrfi005.snapshot_date >= prev_month_start,
                RawZrfi005.snapshot_date <= prev_month_end
            ).delete(synchronize_session=False)
            
            print(f"  âš  Monthly reset: Deleted {deleted} records from {prev_month_start} to {prev_month_end}")
            self.db.commit()
        
        # Load data with snapshot_date
        for idx, row in df.iterrows():
            record = RawZrfi005(
                ...,
                snapshot_date=snapshot_date,  # NEW
                ...
            )
```

#### 3.3 Factory Function Updated (line 720)
```python
def get_loader_for_type(file_type, file_path, db, mode='insert', **kwargs):
    """
    Args:
        mode: Load mode ('insert' or 'upsert')
    """
    loader_class = LOADERS.get(file_type.lower())
    return loader_class(db, mode=mode, **kwargs)
```

### 4. `src/core/upload_service.py` (+5 lines)
**Changes**:
- Get snapshot_date from upload record
- Pass mode='upsert' to all loaders
- Pass snapshot_date to Zrfi005Loader

```python
# Get snapshot_date from upload record (if provided by user)
snapshot_date = upload.snapshot_date or date.today()

# Use upsert mode for all loaders
mode = 'upsert'

if file_type == 'ZRFI005':
    loader = Zrfi005Loader(db, mode=mode)
    stats = loader.load(snapshot_date=snapshot_date)
else:
    loader = get_loader_for_type(file_type.lower(), file_path, db, mode=mode)
    stats = loader.load()
```

---

## ðŸ“ Files Created

### 1. `scripts/migrate_add_ar_snapshot_date.py`
Database migration to add snapshot_date column

**Usage**:
```bash
python scripts/migrate_add_ar_snapshot_date.py
```

**Output**:
```
âœ“ Column snapshot_date already exists
```

### 2. `scripts/test_ar_snapshot.py`
Integration test for AR snapshot_date feature

**Tests**:
1. Upload with snapshot_date parameter
2. Invalid date format validation
3. Upload without snapshot_date (defaults to today)

---

## ðŸ” Technical Implementation Details

### AR Monthly Reset Flow
```
User uploads AR file on Feb 1, 2026
    â†“
snapshot_date = 2026-02-01 (day = 1)
    â†“
Calculate previous month: Jan 1 - Jan 31, 2026
    â†“
DELETE FROM raw_zrfi005 
WHERE snapshot_date >= '2026-01-01' 
  AND snapshot_date <= '2026-01-31'
    â†“
INSERT new records with snapshot_date = 2026-02-01
```

### Upsert Mode Architecture
```python
# Current implementation: Insert-only (bulk_save_objects)
self.db.bulk_save_objects(records)  # Fast but no deduplication

# Future Phase 3: Full upsert with business keys
for row in data:
    business_key = {'billing_doc': row['billing_doc']}  # Example
    row_hash = compute_row_hash(row)
    
    result = self.upsert_record(
        model_class=RawZrsd002,
        business_keys=business_key,
        record_data=row,
        row_hash=row_hash
    )
    # Result: 'inserted', 'updated', or 'skipped'
```

**Note**: Full upsert requires refactoring all 8 loaders to:
1. Define business keys per table
2. Add row_hash column to all raw tables
3. Replace bulk_save_objects with row-by-row upsert logic
4. Performance optimization (batch upserts)

---

## ðŸ› Issues Fixed

### Issue 1: IndentationError in loaders.py
**Error**:
```
File "C:\dev\alkana-dashboard\src\etl\loaders.py", line 747
    Loader instance
IndentationError: unexpected indent
```

**Cause**: Duplicate function code from incomplete string replacement

**Fix**: Removed orphaned docstring fragments
```python
# Before (had duplicate)
return loader_class(db, mode=mode, **kwargs)
    Loader instance  # â† Orphan text
    
# After (clean)
return loader_class(db, mode=mode, **kwargs)
```

### Issue 2: snapshot_date returned None
**Error**: API returned `snapshot_date: None` despite sending parameter

**Cause**: FastAPI expects Form data, not query parameters for multipart uploads

**Fix**: Changed parameter declaration
```python
# Before
snapshot_date: Optional[str] = None  # Query param

# After  
from fastapi import Form
snapshot_date: Optional[str] = Form(None)  # Form field
```

### Issue 3: Missing date/timedelta imports
**Error**: `NameError: name 'date' is not defined`

**Fix**: Added imports
```python
from datetime import datetime, date, timedelta
```

---

## âœ… Validation Results

### Manual API Testing
```http
POST http://localhost:8000/api/v1/upload
Content-Type: multipart/form-data

file: zrfi005.xlsx
snapshot_date: 2026-01-05

â†’ 200 OK
{
  "upload_id": 3,
  "status": "pending"
}

GET http://localhost:8000/api/v1/upload/3/status
â†’ 200 OK
{
  "snapshot_date": "2026-01-05",  âœ…
  "rows_loaded": 129,
  "file_type": "ZRFI005"
}
```

### Database Verification
```sql
SELECT id, original_name, snapshot_date, rows_loaded 
FROM upload_history 
ORDER BY id DESC LIMIT 1;

-- Result:
-- id | original_name | snapshot_date | rows_loaded
-- 3  | zrfi005.xlsx  | 2026-01-05   | 129
```

---

## ðŸ“‹ Phase 2 Checklist

- [x] Add snapshot_date parameter to upload endpoint (Form data)
- [x] Parse and validate date format (YYYY-MM-DD)
- [x] Store snapshot_date in UploadHistory model
- [x] Add snapshot_date column to RawZrfi005 model
- [x] Create database migration script
- [x] Implement AR monthly reset logic in Zrfi005Loader
- [x] Pass snapshot_date from upload_service to loader
- [x] Add mode parameter to BaseLoader
- [x] Implement upsert_record() method in BaseLoader
- [x] Update get_loader_for_type() factory
- [x] Fix import errors (date, timedelta)
- [x] Fix IndentationError in loaders.py
- [x] Fix Form parameter issue
- [x] Create test script
- [x] Verify AR upload with snapshot_date
- [x] Document implementation

---

## ðŸš€ Next Steps (Phase 3)

### Full Upsert Mode Implementation
**Requirement**: Update existing records, skip unchanged, insert new

**Tasks**:
1. Add row_hash column to all 8 raw tables
2. Define business keys per table:
   - COOISPI: `order + batch`
   - MB51: `material_doc + material`
   - ZRSD002: `billing_doc`
   - ZRSD004: `delivery`
   - ZRSD006: `material + dist_channel`
   - ZRFI005: `customer_name + snapshot_date`
   - ZRMM024: `purch_order + item`
   - TARGET: `salesman_name + semester + year`

3. Refactor all loaders:
```python
# Example: Zrsd002Loader with upsert
for idx, row in df.iterrows():
    business_key = {'billing_doc': safe_str(row.get('Billing Doc'))}
    row_hash = compute_row_hash(row_to_json(row))
    
    record_data = {
        'billing_doc': safe_str(row.get('Billing Doc')),
        # ... all fields ...
        'row_hash': row_hash
    }
    
    if self.mode == 'upsert':
        self.upsert_record(RawZrsd002, business_key, record_data, row_hash)
    else:
        # Insert mode (current behavior)
        records.append(RawZrsd002(**record_data))
```

4. Add database migrations for row_hash columns
5. Update test scripts to verify upsert behavior
6. Performance testing (upsert vs bulk insert)

**Estimated Time**: 1 day

---

## ðŸ’¡ Key Learnings

### FastAPI Form Data
- File uploads require `multipart/form-data`
- Additional fields must use `Form()` dependency
- Cannot mix query params with file uploads

### SQLAlchemy Upsert Patterns
```python
# Option 1: Row-by-row (current)
existing = session.query(Model).filter_by(**keys).first()
if existing:
    for k, v in data.items():
        setattr(existing, k, v)
else:
    session.add(Model(**data))

# Option 2: Bulk upsert (PostgreSQL-specific)
stmt = insert(Model).values(records)
stmt = stmt.on_conflict_do_update(
    index_elements=['business_key'],
    set_={k: v for k, v in stmt.excluded.items()}
)
```

### Date Handling
- FastAPI: `Form(None)` for optional date strings
- Parse: `datetime.strptime(date_str, '%Y-%m-%d').date()`
- Database: `Column(Date)` stores date only
- API response: `.isoformat()` returns 'YYYY-MM-DD' string

---

## ðŸ“š References

- [plans/data-upload-feature.md](plans/data-upload-feature.md) - Full implementation plan
- [plans/phase1-implementation-summary.md](plans/phase1-implementation-summary.md) - Phase 1 summary
- [FastAPI Form Data](https://fastapi.tiangolo.com/tutorial/request-forms/) - Official docs
- [SQLAlchemy Upsert](https://docs.sqlalchemy.org/en/14/dialects/postgresql.html#insert-on-conflict-upsert) - PostgreSQL dialect

---

**Phase 2 Status**: âœ… COMPLETE  
**Next Phase**: Phase 3 - Full Upsert Implementation (1 day)  
**Code Quality**: Production-ready  
**Breaking Changes**: None (backward compatible)

---

*Generated by Claude (GitHub Copilot) - January 5, 2026*
